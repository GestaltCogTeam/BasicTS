{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_path = os.path.abspath(os.getcwd())\n",
    "PROJECT_DIR = os.path.abspath(\"../..\")\n",
    "print(PROJECT_DIR)\n",
    "os.chdir(PROJECT_DIR)\n",
    "sys.path.append(PROJECT_DIR)\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import torch\n",
    "from pmdarima import auto_arima\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from basicts.utils import load_pkl, get_regular_settings\n",
    "from basicts.data import TimeSeriesForecastingDataset\n",
    "from basicts.metrics import masked_mae, masked_rmse, masked_mape, masked_mse\n",
    "from basicts.scaler import ZScoreScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct configs\n",
    "dataset_name = \"ETTh1\"\n",
    "\n",
    "regular_settings = get_regular_settings(dataset_name)\n",
    "\n",
    "input_len = 96 #regular_settings['INPUT_LEN']\n",
    "output_len = 96 #regular_settings['OUTPUT_LEN']\n",
    "rescale = regular_settings['RESCALE']\n",
    "null_val = regular_settings['NULL_VAL']\n",
    "norm_each_channel = regular_settings['NORM_EACH_CHANNEL']\n",
    "train_val_test_ratio = regular_settings['TRAIN_VAL_TEST_RATIO']\n",
    "\n",
    "target_time_series = None # for subset forecasting\n",
    "\n",
    "gpu_num = 1\n",
    "batch_size = 128 # only used for collecting data\n",
    "\n",
    "# MA params\n",
    "params = {\n",
    "    'start_p': 0,            # The MA model is unrelated to it. Lower bound of parameter p (int). Default = 2\n",
    "    'd': 0,                  # The MA model is unrelated to it. Non-seasonal differencing order (int). Default = None (auto selection, but increases runtime)\n",
    "    'start_q': 1,            # Lower bound of parameter q (int). Default = 2\n",
    "    'max_p': 0,              # The MA model is unrelated to it. Upper bound of parameter p (int). Default = 5 (must be >= start_p)\n",
    "    'max_q': 5,              #  Upper bound of parameter q (int). Default = 5 (must be >= start_q)\n",
    "    'D': None,               # Seasonal differencing order (int). Default = None (auto selection)\n",
    "    'stationary': True,      # The MA model assumes that time series are stationary. Whether the time series is stationary (bool). Default = False\n",
    "    'transparams':True,\n",
    "    'seasonal': False,       # The MA model is unrelated to it. Whether to fit seasonal ARIMA (bool). Default = True (set to False if m=1)\n",
    "    'm': 1,                  # The number of periods in each season (int). Default = 1 (e.g. 12 for monthly data, 4 for quarterly)\n",
    "    'error_action': 'ignore',# How to handle errors (str). Default = 'trace'. Options: 'warn','raise','ignore','trace'\n",
    "    'suppress_warnings': True,# Whether to suppress warnings (bool). Default = True\n",
    "    'stepwise': True,        # Whether to use stepwise search algorithm (bool). Default = True (faster, but may miss best model)\n",
    "    'n_jobs': 1,              # Number of models to fit in parallel (int). Default = 1. If -1, use all processors\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = TimeSeriesForecastingDataset(dataset_name=dataset_name, input_len=input_len, output_len=output_len, train_val_test_ratio=train_val_test_ratio, mode=\"test\")\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "scaler = ZScoreScaler(dataset_name=dataset_name, train_ratio=train_val_test_ratio[0], norm_each_channel=norm_each_channel, rescale=rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_test = []\n",
    "Ys_test = []\n",
    "\n",
    "def preprocessing(input_data, scaler, target_time_series) -> Dict:\n",
    "    if scaler is not None:\n",
    "        input_data['target'] = scaler.transform(input_data['target'])\n",
    "        input_data['inputs'] = scaler.transform(input_data['inputs'])\n",
    "    if target_time_series is not None:\n",
    "        input_data['target'] = input_data['target'][:, :, target_time_series, :]\n",
    "        input_data['inputs'] = input_data['inputs'][:, :, target_time_series, :]\n",
    "    return input_data\n",
    "\n",
    "# Local forecasting\n",
    "# Test dataset only\n",
    "for i, iter_data in enumerate(test_loader):\n",
    "    iter_data = preprocessing(iter_data, scaler=scaler, target_time_series=target_time_series)\n",
    "    inputs, target = iter_data['inputs'], iter_data['target']\n",
    "    Xs_test.append(inputs)\n",
    "    Ys_test.append(target)\n",
    "\n",
    "\n",
    "Xs_test = torch.cat(Xs_test, dim=0)[..., [0]]\n",
    "Xs_test = Xs_test[::input_len,:,:,:] # The time complexity of method is so high that we have to sample at intervals to test its performance.\n",
    "Ys_test = torch.cat(Ys_test, dim=0)[..., [0]]\n",
    "Ys_test = Ys_test[::input_len,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(data):\n",
    "    B, L, N, C = data.shape\n",
    "    data = data[..., 0].transpose(1, 2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N, L = reshape(Xs_test).shape\n",
    "B, N, L2 = reshape(Ys_test).shape\n",
    "result = np.zeros((B, N, L2))\n",
    "Xs_test = reshape(Xs_test).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Direct Multi-Step Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting and Forecasting Functions\n",
    "def fit_and_forecast(i, j, params):\n",
    "    data = Xs_test[i, j, :] + 0.00001 # overcome the zero issue\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    estimator = auto_arima(data, **params)\n",
    "    # Fitting\n",
    "    models = estimator.fit(data)\n",
    "    # Forecasting\n",
    "    forecast = models.predict(n_periods=L2) - 0.00001\n",
    "    return i, j, forecast\n",
    "\n",
    "print(Xs_test.shape)\n",
    "# Create task list\n",
    "tasks = [(i, j) for i in range(B) for j in range(N)]\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(fit_and_forecast)(i, j, params) for i, j in tqdm(tasks, desc=\"Processing batches and series\")\n",
    ")\n",
    "\n",
    "for i, j, forecast in results:\n",
    "    result[i, j, :] = forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test (Direct Multi-Step Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys_test = reshape(Ys_test)\n",
    "B, N, L = Ys_test.shape\n",
    "prediction = torch.tensor(result).reshape(B, N, L)\n",
    "real_value = Ys_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(\"MAE: \", masked_mae(prediction, real_value, null_val).item())\n",
    "print(\"RMSE: \", masked_rmse(prediction, real_value, null_val).item())\n",
    "print(\"MSE: \", masked_mse(prediction, real_value, null_val).item())\n",
    "print(\"MAPE: {:.2f}%\".format(masked_mape(prediction, real_value, null_val) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(prediction.shape)\n",
    "B_index = 0  # Select an index in dimension B\n",
    "N_index = 0  # Select an index in dimension N\n",
    "\n",
    "predicted_values = prediction[B_index, N_index, :]  # shape: (L,)\n",
    "true_values = Ys_test[B_index, N_index, :]  # shape: (L,)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(predicted_values, label='Predicted', color='blue', linestyle='--')\n",
    "plt.plot(true_values, label='True', color='red', linestyle='-')\n",
    "plt.xlabel('Time Step (L)')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'Prediction vs True Values (B={B_index}, N={N_index})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
